# Real-Time Edge Inference Optimization on NVIDIA Jetson Orin
## Constraint
What had to be fast, how fast?
## System
What components exist? Where does data flow?
## Baseline
What was the naive implementation?
## Measurement
How was performance measured?
## Bottleneck
What dominated latency?
## Intervention
What change targeted the bottleneck?
## Result
What changed numerically?
## Tradeoff
What got worse or riskier?
## Next Step
What is the next bottleneck?

